{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wFY7-B9UwiSN"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Load the California housing dataset\n",
        "data = fetch_california_housing()\n",
        "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "y = data.target\n",
        "\n",
        "# Feature engineering: Add polynomial and interaction features\n",
        "poly_transformer = PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)\n",
        "X_poly = poly_transformer.fit_transform(X)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_poly, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define a pipeline with feature scaling, polynomial feature generation, and a gradient boosting regressor\n",
        "pipeline = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('poly', PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)),\n",
        "    ('gbr', GradientBoostingRegressor(random_state=42))\n",
        "])\n",
        "\n",
        "# Hyperparameter tuning using GridSearchCV\n",
        "param_grid = {\n",
        "    'gbr__n_estimators': [100, 125, 150, 200],\n",
        "    'gbr__max_depth': [3, 4],\n",
        "    'gbr__learning_rate': [0.1, 0.05]\n",
        "}\n",
        "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Print the best parameters\n",
        "print(\"Best parameters:\", grid_search.best_params_)\n",
        "\n",
        "# Use the best model\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "# Make predictions on the testing set\n",
        "y_pred = best_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r_squared = r2_score(y_test, y_pred)\n",
        "\n",
        "# Print the metrics\n",
        "print(\"Mean Squared Error (MSE):\", mse)\n",
        "print(\"R-squared:\", r_squared)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
        "from sklearn.pipeline import Pipeline"
      ],
      "metadata": {
        "id": "3ocNKWjU8pDU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the California housing dataset\n",
        "data = fetch_california_housing()\n",
        "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "y = data.target"
      ],
      "metadata": {
        "id": "21I33bNL8wZ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature engineering: Add polynomial and interaction features\n",
        "poly_transformer = PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)\n",
        "X_poly = poly_transformer.fit_transform(X)"
      ],
      "metadata": {
        "id": "uHkFaSHJ80Ts"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_poly, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "Xgtxp_kl84Mq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a pipeline with feature scaling, polynomial feature generation, and a gradient boosting regressor\n",
        "pipeline = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('poly', PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)),\n",
        "    ('gbr', GradientBoostingRegressor(random_state=42))\n",
        "])"
      ],
      "metadata": {
        "id": "Y3qdO4hf867r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameter tuning using GridSearchCV\n",
        "param_grid = {\n",
        "    'gbr__n_estimators': [100, 120],\n",
        "    'gbr__max_depth': [3, 4],\n",
        "    'gbr__learning_rate': [0.1, 0.05]\n",
        "}\n",
        "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
        "grid_search.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "lNGgEjkK8-BY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The GridSearchCV function in the code will run a grid search to evaluate different combinations of parameters specified in the param_grid. The total number of loops or iterations the grid search will run is determined by the number of combinations of parameters and the number of folds used for cross-validation (cv).\n",
        "\n",
        "In the param_grid, there are:\n",
        "\n",
        "2 options for 'gbr__n_estimators'\n",
        "2 options for 'gbr__max_depth'\n",
        "2 options for 'gbr__learning_rate'\n",
        "This results in a total of 2 * 2 * 2 = 8 combinations of parameters.\n",
        "\n",
        "Since the cross-validation (cv) is set to 5, each combination of parameters will be evaluated 5 times (once for each fold).\n",
        "\n",
        "Therefore, the total number of loops or model fits that will be run is 8 combinations * 5 folds = 40 loops."
      ],
      "metadata": {
        "id": "5GPQrmA2-eBG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the best parameters\n",
        "print(\"Best parameters:\", grid_search.best_params_)"
      ],
      "metadata": {
        "id": "b5mZkvY69Bgi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the best model\n",
        "best_model = grid_search.best_estimator_\n"
      ],
      "metadata": {
        "id": "_J8_HY689DLU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on the testing set\n",
        "y_pred = best_model.predict(X_test)"
      ],
      "metadata": {
        "id": "wdWfsS8S9Ev3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r_squared = r2_score(y_test, y_pred)"
      ],
      "metadata": {
        "id": "GqxZeJJ_9Gos"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the metrics\n",
        "print(\"Mean Squared Error (MSE):\", mse)\n",
        "print(\"R-squared:\", r_squared)"
      ],
      "metadata": {
        "id": "r1kCVDnG9IM-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}